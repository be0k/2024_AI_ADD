{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4503e2",
   "metadata": {},
   "source": [
    "# 중요\n",
    "### unlabeled_data 이름 저장과 32000 to 16000은 train을 위한 필수 파일입니다.(안만들면 오류가 납니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797363ec-ec33-4eb1-b0d3-c813b4c78b25",
   "metadata": {},
   "source": [
    "### 1. login Huggingface(token type = write)\n",
    "### 2. get permission   \n",
    "###    https://huggingface.co/pyannote/speaker-diarization-3.1     \n",
    "###    and   \n",
    "###    https://huggingface.co/pyannote/segmentation-3.0\n",
    "\n",
    "권한 안얻으시면 오류납니다.\n",
    "위에 있는 두 모델은 주최측에서 사용가능하다고한 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa1835-3f7e-4b7d-b82f-91230acd5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a267c53-59b5-4000-9453-3e1a3d2f3075",
   "metadata": {},
   "source": [
    "# unlabeled data name save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81094a71-80c6-40ef-ab4d-1b7beef73838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "id = []\n",
    "for i in os.listdir('unlabeled_data'):\n",
    "    id.append(i[:-4])\n",
    "\n",
    "pd.Series(id).to_csv('unlabeled.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8607e13",
   "metadata": {},
   "source": [
    "# speaker diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f15ee93-6921-486d-9aa4-3c8e0674f689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1907022eada54fe2b268cb847c7bc03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=True)\n",
    "\n",
    "pipeline.to(torch.device('cuda'))\n",
    "cnt = []\n",
    "for file_path in tqdm(df['id']):\n",
    "    diarization = pipeline(f'test/{file_path}.ogg', min_speakers=0, max_speakers=2)\n",
    "    \n",
    "    # 화자 수 추정\n",
    "    speakers = set()\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        speakers.add(speaker)\n",
    "    \n",
    "    cnt.append(len(speakers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0c781",
   "metadata": {},
   "source": [
    "# Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904e908a-1cdf-47da-8121-2d12ecc3e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pd.DataFrame({\n",
    "    'id':df['id'],\n",
    "    'count':np.array(cnt)}).to_csv('test_count_32000.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ffd609-3752-415d-a7a8-4acdf4fbfb9f",
   "metadata": {},
   "source": [
    "# 32000 to 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1714b45-8629-4b29-add5-cbd5ac7c21f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ec16713ef34ae4aedab7a2a2bf0926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train files have been converted and saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0941ef2d847411b860158f3aa14ee8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test files have been converted and saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0b6c3ff60b49649e6d8f6d9e4a4349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlabeled_data files have been converted and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def low_level_audio(f_name):\n",
    "    # 원본 .ogg 파일이 있는 폴더 경로\n",
    "    input_folder = f_name\n",
    "    # 변환된 .wav 파일을 저장할 폴더 경로\n",
    "    output_folder = f'{f_name}tmp'\n",
    "    \n",
    "    # 출력 폴더가 존재하지 않으면 생성\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # input_folder 안의 모든 파일을 순회\n",
    "    for filename in tqdm(os.listdir(input_folder)):\n",
    "        if filename.endswith('.ogg'):\n",
    "            # 파일 경로 생성\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            # .ogg 파일 불러오기\n",
    "            y, sr = librosa.load(input_path, sr=32000)\n",
    "            \n",
    "            # 샘플링 레이트를 16000으로 변환\n",
    "            y_resampled = librosa.resample(y, orig_sr=32000, target_sr=16000)\n",
    "            \n",
    "            # 새로운 파일 경로 생성 (확장자 변경)\n",
    "            output_filename = os.path.splitext(filename)[0] + '.wav'\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            \n",
    "            # .wav 파일로 저장\n",
    "            sf.write(output_path, y_resampled, 16000)\n",
    "            \n",
    "    print(f\"{f_name} files have been converted and saved.\")\n",
    "\n",
    "\n",
    "low_level_audio('train')\n",
    "low_level_audio('test')\n",
    "low_level_audio('unlabeled_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c52f656-b95c-4dbe-9e2f-3787a9480c97",
   "metadata": {},
   "source": [
    "# 학습 코드는 따로 올려놨습니다.\n",
    "## only inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baed220f-c740-46ff-b185-44b3e255748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_weight/fold'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704b56b",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cf39369-fa64-4a9e-a893-269b076b320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from scipy import signal\n",
    "import copy\n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import brentq\n",
    "from sklearn.metrics import roc_curve, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "#hf\n",
    "from transformers import (AutoConfig,AutoModel)\n",
    "\n",
    "#torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "#librosa\n",
    "import librosa\n",
    "\n",
    "#wandb\n",
    "import wandb\n",
    "\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6385eddd",
   "metadata": {},
   "source": [
    "# AASIST Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1461f0b0-14c6-49a2-ad58-a60dd69da2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # attention map\n",
    "        self.att_proj = nn.Linear(in_dim, out_dim)\n",
    "        self.att_weight = self._init_new_params(out_dim, 1)\n",
    "\n",
    "        # project\n",
    "        self.proj_with_att = nn.Linear(in_dim, out_dim)\n",
    "        self.proj_without_att = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "        # batch norm\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "        # dropout for inputs\n",
    "        self.input_drop = nn.Dropout(p=0.2)\n",
    "\n",
    "        # activate\n",
    "        self.act = nn.SELU(inplace=True)\n",
    "\n",
    "        # temperature\n",
    "        self.temp = 1.\n",
    "        if \"temperature\" in kwargs:\n",
    "            self.temp = kwargs[\"temperature\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x   :(#bs, #node, #dim)\n",
    "        '''\n",
    "        # apply input dropout\n",
    "        x = self.input_drop(x)\n",
    "\n",
    "        # derive attention map\n",
    "        att_map = self._derive_att_map(x)\n",
    "\n",
    "        # projection\n",
    "        x = self._project(x, att_map)\n",
    "\n",
    "        # apply batch norm\n",
    "        x = self._apply_BN(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "    def _pairwise_mul_nodes(self, x):\n",
    "        '''\n",
    "        Calculates pairwise multiplication of nodes.\n",
    "        - for attention map\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, #dim)\n",
    "        '''\n",
    "\n",
    "        nb_nodes = x.size(1)\n",
    "        x = x.unsqueeze(2).expand(-1, -1, nb_nodes, -1)\n",
    "        x_mirror = x.transpose(1, 2)\n",
    "\n",
    "        return x * x_mirror\n",
    "\n",
    "    def _derive_att_map(self, x):\n",
    "        '''\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, 1)\n",
    "        '''\n",
    "        att_map = self._pairwise_mul_nodes(x)\n",
    "        # size: (#bs, #node, #node, #dim_out)\n",
    "        att_map = torch.tanh(self.att_proj(att_map))\n",
    "        # size: (#bs, #node, #node, 1)\n",
    "        att_map = torch.matmul(att_map, self.att_weight)\n",
    "\n",
    "        # apply temperature\n",
    "        att_map = att_map / self.temp\n",
    "\n",
    "        att_map = F.softmax(att_map, dim=-2)\n",
    "\n",
    "        return att_map\n",
    "\n",
    "    def _project(self, x, att_map):\n",
    "        x1 = self.proj_with_att(torch.matmul(att_map.squeeze(-1), x))\n",
    "        x2 = self.proj_without_att(x)\n",
    "\n",
    "        return x1 + x2\n",
    "\n",
    "    def _apply_BN(self, x):\n",
    "        org_size = x.size()\n",
    "        x = x.view(-1, org_size[-1])\n",
    "        x = self.bn(x)\n",
    "        x = x.view(org_size)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_new_params(self, *size):\n",
    "        out = nn.Parameter(torch.FloatTensor(*size))\n",
    "        nn.init.xavier_normal_(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class HtrgGraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj_type1 = nn.Linear(in_dim, in_dim)\n",
    "        self.proj_type2 = nn.Linear(in_dim, in_dim)\n",
    "\n",
    "        # attention map\n",
    "        self.att_proj = nn.Linear(in_dim, out_dim)\n",
    "        self.att_projM = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "        self.att_weight11 = self._init_new_params(out_dim, 1)\n",
    "        self.att_weight22 = self._init_new_params(out_dim, 1)\n",
    "        self.att_weight12 = self._init_new_params(out_dim, 1)\n",
    "        self.att_weightM = self._init_new_params(out_dim, 1)\n",
    "\n",
    "        # project\n",
    "        self.proj_with_att = nn.Linear(in_dim, out_dim)\n",
    "        self.proj_without_att = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "        self.proj_with_attM = nn.Linear(in_dim, out_dim)\n",
    "        self.proj_without_attM = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "        # batch norm\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "        # dropout for inputs\n",
    "        self.input_drop = nn.Dropout(p=0.2)\n",
    "\n",
    "        # activate\n",
    "        self.act = nn.SELU(inplace=True)\n",
    "\n",
    "        # temperature\n",
    "        self.temp = 1.\n",
    "        if \"temperature\" in kwargs:\n",
    "            self.temp = kwargs[\"temperature\"]\n",
    "\n",
    "    def forward(self, x1, x2, master=None):\n",
    "        '''\n",
    "        x1  :(#bs, #node, #dim)\n",
    "        x2  :(#bs, #node, #dim)\n",
    "        '''\n",
    "        num_type1 = x1.size(1)\n",
    "        num_type2 = x2.size(1)\n",
    "\n",
    "        x1 = self.proj_type1(x1)\n",
    "        x2 = self.proj_type2(x2)\n",
    "\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        if master is None:\n",
    "            master = torch.mean(x, dim=1, keepdim=True)\n",
    "\n",
    "        # apply input dropout\n",
    "        x = self.input_drop(x)\n",
    "\n",
    "        # derive attention map\n",
    "        att_map = self._derive_att_map(x, num_type1, num_type2)\n",
    "\n",
    "        # directional edge for master node\n",
    "        master = self._update_master(x, master)\n",
    "\n",
    "        # projection\n",
    "        x = self._project(x, att_map)\n",
    "\n",
    "        # apply batch norm\n",
    "        x = self._apply_BN(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x1 = x.narrow(1, 0, num_type1)\n",
    "        x2 = x.narrow(1, num_type1, num_type2)\n",
    "\n",
    "        return x1, x2, master\n",
    "\n",
    "    def _update_master(self, x, master):\n",
    "\n",
    "        att_map = self._derive_att_map_master(x, master)\n",
    "        master = self._project_master(x, master, att_map)\n",
    "\n",
    "        return master\n",
    "\n",
    "    def _pairwise_mul_nodes(self, x):\n",
    "        '''\n",
    "        Calculates pairwise multiplication of nodes.\n",
    "        - for attention map\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, #dim)\n",
    "        '''\n",
    "\n",
    "        nb_nodes = x.size(1)\n",
    "        x = x.unsqueeze(2).expand(-1, -1, nb_nodes, -1)\n",
    "        x_mirror = x.transpose(1, 2)\n",
    "\n",
    "        return x * x_mirror\n",
    "\n",
    "    def _derive_att_map_master(self, x, master):\n",
    "        '''\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, 1)\n",
    "        '''\n",
    "        att_map = x * master\n",
    "        att_map = torch.tanh(self.att_projM(att_map))\n",
    "\n",
    "        att_map = torch.matmul(att_map, self.att_weightM)\n",
    "\n",
    "        # apply temperature\n",
    "        att_map = att_map / self.temp\n",
    "\n",
    "        att_map = F.softmax(att_map, dim=-2)\n",
    "\n",
    "        return att_map\n",
    "\n",
    "    def _derive_att_map(self, x, num_type1, num_type2):\n",
    "        '''\n",
    "        x           :(#bs, #node, #dim)\n",
    "        out_shape   :(#bs, #node, #node, 1)\n",
    "        '''\n",
    "        att_map = self._pairwise_mul_nodes(x)\n",
    "        # size: (#bs, #node, #node, #dim_out)\n",
    "        att_map = torch.tanh(self.att_proj(att_map))\n",
    "        # size: (#bs, #node, #node, 1)\n",
    "\n",
    "        att_board = torch.zeros_like(att_map[:, :, :, 0]).unsqueeze(-1)\n",
    "\n",
    "        att_board[:, :num_type1, :num_type1, :] = torch.matmul(\n",
    "            att_map[:, :num_type1, :num_type1, :], self.att_weight11)\n",
    "        att_board[:, num_type1:, num_type1:, :] = torch.matmul(\n",
    "            att_map[:, num_type1:, num_type1:, :], self.att_weight22)\n",
    "        att_board[:, :num_type1, num_type1:, :] = torch.matmul(\n",
    "            att_map[:, :num_type1, num_type1:, :], self.att_weight12)\n",
    "        att_board[:, num_type1:, :num_type1, :] = torch.matmul(\n",
    "            att_map[:, num_type1:, :num_type1, :], self.att_weight12)\n",
    "\n",
    "        att_map = att_board\n",
    "\n",
    "        # att_map = torch.matmul(att_map, self.att_weight12)\n",
    "\n",
    "        # apply temperature\n",
    "        att_map = att_map / self.temp\n",
    "\n",
    "        att_map = F.softmax(att_map, dim=-2)\n",
    "\n",
    "        return att_map\n",
    "\n",
    "    def _project(self, x, att_map):\n",
    "        x1 = self.proj_with_att(torch.matmul(att_map.squeeze(-1), x))\n",
    "        x2 = self.proj_without_att(x)\n",
    "\n",
    "        return x1 + x2\n",
    "\n",
    "    def _project_master(self, x, master, att_map):\n",
    "\n",
    "        x1 = self.proj_with_attM(torch.matmul(\n",
    "            att_map.squeeze(-1).unsqueeze(1), x))\n",
    "        x2 = self.proj_without_attM(master)\n",
    "\n",
    "        return x1 + x2\n",
    "\n",
    "    def _apply_BN(self, x):\n",
    "        org_size = x.size()\n",
    "        x = x.view(-1, org_size[-1])\n",
    "        x = self.bn(x)\n",
    "        x = x.view(org_size)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_new_params(self, *size):\n",
    "        out = nn.Parameter(torch.FloatTensor(*size))\n",
    "        nn.init.xavier_normal_(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class GraphPool(nn.Module):\n",
    "    def __init__(self, k: float, in_dim: int, p: Union[float, int]):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.proj = nn.Linear(in_dim, 1)\n",
    "        self.drop = nn.Dropout(p=p) if p > 0 else nn.Identity()\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "    def forward(self, h):\n",
    "        Z = self.drop(h)\n",
    "        weights = self.proj(Z)\n",
    "        scores = self.sigmoid(weights)\n",
    "        new_h = self.top_k_graph(scores, h, self.k)\n",
    "\n",
    "        return new_h\n",
    "\n",
    "    def top_k_graph(self, scores, h, k):\n",
    "        \"\"\"\n",
    "        args\n",
    "        =====\n",
    "        scores: attention-based weights (#bs, #node, 1)\n",
    "        h: graph data (#bs, #node, #dim)\n",
    "        k: ratio of remaining nodes, (float)\n",
    "\n",
    "        returns\n",
    "        =====\n",
    "        h: graph pool applied data (#bs, #node', #dim)\n",
    "        \"\"\"\n",
    "        _, n_nodes, n_feat = h.size()\n",
    "        n_nodes = max(int(n_nodes * k), 1)\n",
    "        _, idx = torch.topk(scores, n_nodes, dim=1)\n",
    "        idx = idx.expand(-1, -1, n_feat)\n",
    "\n",
    "        h = h * scores\n",
    "        h = torch.gather(h, 1, idx)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class CONV(nn.Module):\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 sample_rate=16000,\n",
    "                 in_channels=1,\n",
    "                 stride=1,\n",
    "                 padding=0,\n",
    "                 dilation=1,\n",
    "                 bias=False,\n",
    "                 groups=1,\n",
    "                 mask=False):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "\n",
    "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (\n",
    "                in_channels)\n",
    "            raise ValueError(msg)\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "        if kernel_size % 2 == 0:\n",
    "            self.kernel_size = self.kernel_size + 1\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.mask = mask\n",
    "        if bias:\n",
    "            raise ValueError('SincConv does not support bias.')\n",
    "        if groups > 1:\n",
    "            raise ValueError('SincConv does not support groups.')\n",
    "\n",
    "        NFFT = 512\n",
    "        f = int(self.sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        fmelmax = np.max(fmel)\n",
    "        fmelmin = np.min(fmel)\n",
    "        filbandwidthsmel = np.linspace(fmelmin, fmelmax, self.out_channels + 1)\n",
    "        filbandwidthsf = self.to_hz(filbandwidthsmel)\n",
    "\n",
    "        self.mel = filbandwidthsf\n",
    "        self.hsupp = torch.arange(-(self.kernel_size - 1) / 2,\n",
    "                                  (self.kernel_size - 1) / 2 + 1)\n",
    "        self.band_pass = torch.zeros(self.out_channels, self.kernel_size)\n",
    "        for i in range(len(self.mel) - 1):\n",
    "            fmin = self.mel[i]\n",
    "            fmax = self.mel[i + 1]\n",
    "            hHigh = (2*fmax/self.sample_rate) * \\\n",
    "                np.sinc(2*fmax*self.hsupp/self.sample_rate)\n",
    "            hLow = (2*fmin/self.sample_rate) * \\\n",
    "                np.sinc(2*fmin*self.hsupp/self.sample_rate)\n",
    "            hideal = hHigh - hLow\n",
    "\n",
    "            self.band_pass[i, :] = Tensor(np.hamming(\n",
    "                self.kernel_size)) * Tensor(hideal)\n",
    "\n",
    "    def forward(self, x, mask=False):\n",
    "        band_pass_filter = self.band_pass.clone().to(x.device)\n",
    "        if mask:\n",
    "            A = np.random.uniform(0, 20)\n",
    "            A = int(A)\n",
    "            A0 = random.randint(0, band_pass_filter.shape[0] - A)\n",
    "            band_pass_filter[A0:A0 + A, :] = 0\n",
    "        else:\n",
    "            band_pass_filter = band_pass_filter\n",
    "\n",
    "        self.filters = (band_pass_filter).view(self.out_channels, 1,\n",
    "                                               self.kernel_size)\n",
    "\n",
    "        return F.conv1d(x,\n",
    "                        self.filters,\n",
    "                        stride=self.stride,\n",
    "                        padding=self.padding,\n",
    "                        dilation=self.dilation,\n",
    "                        bias=None,\n",
    "                        groups=1)\n",
    "\n",
    "\n",
    "class Residual_block(nn.Module):\n",
    "    def __init__(self, nb_filts, first=False):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "\n",
    "        if not self.first:\n",
    "            self.bn1 = nn.BatchNorm2d(num_features=nb_filts[0])\n",
    "        self.conv1 = nn.Conv2d(in_channels=nb_filts[0],\n",
    "                               out_channels=nb_filts[1],\n",
    "                               kernel_size=(2, 3),\n",
    "                               padding=(1, 1),\n",
    "                               stride=1)\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=nb_filts[1])\n",
    "        self.conv2 = nn.Conv2d(in_channels=nb_filts[1],\n",
    "                               out_channels=nb_filts[1],\n",
    "                               kernel_size=(2, 3),\n",
    "                               padding=(0, 1),\n",
    "                               stride=1)\n",
    "\n",
    "        if nb_filts[0] != nb_filts[1]:\n",
    "            self.downsample = True\n",
    "            self.conv_downsample = nn.Conv2d(in_channels=nb_filts[0],\n",
    "                                             out_channels=nb_filts[1],\n",
    "                                             padding=(0, 1),\n",
    "                                             kernel_size=(1, 3),\n",
    "                                             stride=1)\n",
    "\n",
    "        else:\n",
    "            self.downsample = False\n",
    "        self.mp = nn.MaxPool2d((1, 3))  # self.mp = nn.MaxPool2d((1,4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if not self.first:\n",
    "            out = self.bn1(x)\n",
    "            out = self.selu(out)\n",
    "        else:\n",
    "            out = x\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        # print('out',out.shape)\n",
    "        out = self.bn2(out)\n",
    "        out = self.selu(out)\n",
    "        # print('out',out.shape)\n",
    "        out = self.conv2(out)\n",
    "        #print('conv2 out',out.shape)\n",
    "        if self.downsample:\n",
    "            identity = self.conv_downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.mp(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, d_args):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_args = d_args\n",
    "        filts = d_args[\"filts\"]\n",
    "        gat_dims = d_args[\"gat_dims\"]\n",
    "        pool_ratios = d_args[\"pool_ratios\"]\n",
    "        temperatures = d_args[\"temperatures\"]\n",
    "\n",
    "        self.conv_time = CONV(out_channels=filts[0],\n",
    "                              kernel_size=d_args[\"first_conv\"],\n",
    "                              in_channels=1)\n",
    "        self.first_bn = nn.BatchNorm2d(num_features=1)\n",
    "\n",
    "        self.drop = nn.Dropout(0.5, inplace=True)\n",
    "        self.drop_way = nn.Dropout(0.2, inplace=True)\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[2])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[3])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
    "            nn.Sequential(Residual_block(nb_filts=filts[4])))\n",
    "\n",
    "        self.pos_S = nn.Parameter(torch.randn(1, 23, filts[-1][-1]))\n",
    "        self.master1 = nn.Parameter(torch.randn(1, 1, gat_dims[0]))\n",
    "        self.master2 = nn.Parameter(torch.randn(1, 1, gat_dims[0]))\n",
    "\n",
    "        self.GAT_layer_S = GraphAttentionLayer(filts[-1][-1],\n",
    "                                               gat_dims[0],\n",
    "                                               temperature=temperatures[0])\n",
    "        self.GAT_layer_T = GraphAttentionLayer(filts[-1][-1],\n",
    "                                               gat_dims[0],\n",
    "                                               temperature=temperatures[1])\n",
    "\n",
    "        self.HtrgGAT_layer_ST11 = HtrgGraphAttentionLayer(\n",
    "            gat_dims[0], gat_dims[1], temperature=temperatures[2])\n",
    "        self.HtrgGAT_layer_ST12 = HtrgGraphAttentionLayer(\n",
    "            gat_dims[1], gat_dims[1], temperature=temperatures[2])\n",
    "\n",
    "        self.HtrgGAT_layer_ST21 = HtrgGraphAttentionLayer(\n",
    "            gat_dims[0], gat_dims[1], temperature=temperatures[2])\n",
    "\n",
    "        self.HtrgGAT_layer_ST22 = HtrgGraphAttentionLayer(\n",
    "            gat_dims[1], gat_dims[1], temperature=temperatures[2])\n",
    "\n",
    "        self.pool_S = GraphPool(pool_ratios[0], gat_dims[0], 0.3)\n",
    "        self.pool_T = GraphPool(pool_ratios[1], gat_dims[0], 0.3)\n",
    "        self.pool_hS1 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
    "        self.pool_hT1 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
    "\n",
    "        self.pool_hS2 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
    "        self.pool_hT2 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
    "\n",
    "        self.out_layer = nn.Linear(5 * gat_dims[1], 2)\n",
    "\n",
    "    def forward(self, x, Freq_aug=False):\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv_time(x, mask=Freq_aug)\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = F.max_pool2d(torch.abs(x), (3, 3))\n",
    "        x = self.first_bn(x)\n",
    "        x = self.selu(x)\n",
    "\n",
    "        # get embeddings using encoder\n",
    "        # (#bs, #filt, #spec, #seq)\n",
    "        e = self.encoder(x)\n",
    "\n",
    "        # spectral GAT (GAT-S)\n",
    "        e_S, _ = torch.max(torch.abs(e), dim=3)  # max along time\n",
    "        e_S = e_S.transpose(1, 2) + self.pos_S\n",
    "\n",
    "        gat_S = self.GAT_layer_S(e_S)\n",
    "        out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)\n",
    "\n",
    "        # temporal GAT (GAT-T)\n",
    "        e_T, _ = torch.max(torch.abs(e), dim=2)  # max along freq\n",
    "        e_T = e_T.transpose(1, 2)\n",
    "\n",
    "        gat_T = self.GAT_layer_T(e_T)\n",
    "        out_T = self.pool_T(gat_T)\n",
    "\n",
    "        # learnable master node\n",
    "        master1 = self.master1.expand(x.size(0), -1, -1)\n",
    "        master2 = self.master2.expand(x.size(0), -1, -1)\n",
    "\n",
    "        # inference 1\n",
    "        out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(\n",
    "            out_T, out_S, master=self.master1)\n",
    "\n",
    "        out_S1 = self.pool_hS1(out_S1)\n",
    "        out_T1 = self.pool_hT1(out_T1)\n",
    "\n",
    "        out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(\n",
    "            out_T1, out_S1, master=master1)\n",
    "        out_T1 = out_T1 + out_T_aug\n",
    "        out_S1 = out_S1 + out_S_aug\n",
    "        master1 = master1 + master_aug\n",
    "\n",
    "        # inference 2\n",
    "        out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(\n",
    "            out_T, out_S, master=self.master2)\n",
    "        out_S2 = self.pool_hS2(out_S2)\n",
    "        out_T2 = self.pool_hT2(out_T2)\n",
    "\n",
    "        out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(\n",
    "            out_T2, out_S2, master=master2)\n",
    "        out_T2 = out_T2 + out_T_aug\n",
    "        out_S2 = out_S2 + out_S_aug\n",
    "        master2 = master2 + master_aug\n",
    "\n",
    "        out_T1 = self.drop_way(out_T1)\n",
    "        out_T2 = self.drop_way(out_T2)\n",
    "        out_S1 = self.drop_way(out_S1)\n",
    "        out_S2 = self.drop_way(out_S2)\n",
    "        master1 = self.drop_way(master1)\n",
    "        master2 = self.drop_way(master2)\n",
    "\n",
    "        out_T = torch.max(out_T1, out_T2)\n",
    "        out_S = torch.max(out_S1, out_S2)\n",
    "        master = torch.max(master1, master2)\n",
    "\n",
    "        T_max, _ = torch.max(torch.abs(out_T), dim=1)\n",
    "        T_avg = torch.mean(out_T, dim=1)\n",
    "\n",
    "        S_max, _ = torch.max(torch.abs(out_S), dim=1)\n",
    "        S_avg = torch.mean(out_S, dim=1)\n",
    "\n",
    "        last_hidden = torch.cat(\n",
    "            [T_max, T_avg, S_max, S_avg, master.squeeze(1)], dim=1)\n",
    "\n",
    "        last_hidden = self.drop(last_hidden)\n",
    "        output = self.out_layer(last_hidden)\n",
    "\n",
    "        return output,last_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e64c70",
   "metadata": {},
   "source": [
    "# Dataset Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cc31225-7273-4d3e-8089-a5827a24e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, max_len=80000):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    # need to pad\n",
    "    num_repeats = int(max_len / x_len)+1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    return padded_x\t\n",
    "\n",
    "\n",
    "class Dataset_ASVspoof_eval(Dataset):\n",
    "    def __init__(self, list_IDs):\n",
    "            '''self.list_IDs\t: list of strings (each string: utt key),\n",
    "               '''\n",
    "               \n",
    "            self.list_IDs = list_IDs\n",
    "            self.cut=80000 # take ~4 sec audio (64600 samples)\n",
    "    \n",
    "    def __len__(self):\n",
    "            return len(self.list_IDs)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "            utt_id = self.list_IDs[index]\n",
    "            X, fs = librosa.load('./test16000/'+utt_id+'.wav', sr=16000)\n",
    "            X_pad = pad(X,self.cut)\n",
    "            x_inp = Tensor(X_pad)\n",
    "            return x_inp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd126e96",
   "metadata": {},
   "source": [
    "# Inference function Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a4953e2-e95f-4273-afbf-450d056518f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(data_loader, model, device, save_path):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for features in tqdm(iter(data_loader)):\n",
    "            features = features.to(device)\n",
    "            \n",
    "            probs = torch.sigmoid(model(features)[0])\n",
    "            \n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "    submit = pd.read_csv('./sample_submission.csv')\n",
    "    submit.iloc[:, 1:] = predictions\n",
    "    submit.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8982a7",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efd866-9311-49a5-91b3-d3a0472b45fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea61cabc16e64ec19677d12f2e2d124d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b9880acaa149ccb703d4ea9c01f41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4796be38915a4a25823d969b7e2765c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c9f304cfa143f285b2eb1bbf63f02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9e4388ceda4e8190f29acc70973c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "\n",
    "for_model = {\n",
    "        \"architecture\": \"AASIST\",\n",
    "        \"nb_samp\": 80000,\n",
    "        \"first_conv\": 128,\n",
    "        \"filts\": [70, [1, 32], [32, 32], [32, 64], [64, 64]],\n",
    "        \"gat_dims\": [64, 32],\n",
    "        \"pool_ratios\": [0.5, 0.7, 0.5, 0.5],\n",
    "        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n",
    "    }\n",
    "    \n",
    "classifier = Model(for_model)\n",
    "classifier.to(device)\n",
    "\n",
    "for i in range(5):\n",
    "    classifier.load_state_dict(torch.load(f'{model_path}{i}.pth',map_location=device))\n",
    "    file_eval = pd.read_csv('test.csv')\n",
    "    eval_set = Dataset_ASVspoof_eval(file_eval['id'].to_list())\n",
    "    eval_loader = DataLoader(eval_set, batch_size=16,num_workers=8, shuffle=False)\n",
    "    inference(eval_loader, classifier, device,f'tmp_fold{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f6b23",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fdb67-8585-4c1e-835d-7e5c6fc5515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('tmp_fold0.csv')\n",
    "df0 = pd.read_csv('tmp_fold0.csv')\n",
    "df1 = pd.read_csv('tmp_fold1.csv')\n",
    "df2 = pd.read_csv('tmp_fold2.csv')\n",
    "df3 = pd.read_csv('tmp_fold3.csv')\n",
    "df4 = pd.read_csv('tmp_fold4.csv')\n",
    "df[['fake','real']] = (df0[['fake','real']].values +df1[['fake','real']].values +df2[['fake','real']].values +df3[['fake','real']].values +df4[['fake','real']].values)/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3d880",
   "metadata": {},
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254fe92-a051-4fba-bf7b-07ac99bf0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_df = pd.read_csv('test_count_32000.csv')\n",
    "df.loc[cnt_df['count'] == 0, ['fake', 'real']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135bf03-e008-4304-9efd-ed3376ce1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normal(x):\n",
    "    sum_x = np.sum(x, axis=1, keepdims=True)\n",
    "    return x / sum_x\n",
    "\n",
    "\n",
    "df.loc[cnt_df['count'] == 1, ['fake', 'real']] = (normal(df.loc[cnt_df['count'] == 1, ['fake', 'real']].values) + 0.5)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8199f-e8a7-41c6-8bf8-4a04af74ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def temperature_scaling(logits, temperature=1.1):\n",
    "    # logits을 temperature로 나눈 후 소프트맥스 함수 적용\n",
    "    scaled_logits = logits / temperature\n",
    "    exp_logits = np.exp(scaled_logits)\n",
    "    return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "df.loc[cnt_df['count'] == 2, ['fake', 'real']] = ((temperature_scaling(df.loc[cnt_df['count'] == 2, ['fake', 'real']].values)*4/3)+2/3)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23029715-b6b0-4f01-a24b-4413580a14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['real']>1, ['real']] = 1\n",
    "df.loc[df['fake']>1, ['fake']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d8124-ff70-4775-9cab-5bc1d75e6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submitttt.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
